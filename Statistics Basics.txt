CH1
CH2
CH3
CH4 - Numerical descriptive Techniques
    Measure of linear Relationship
        Covariance, Coefficient of correlation, coefficient of determination
        Covariance - when 2 variable move in the same direction; covariance is large positive #
                     when 2 variable move in the opp direction; covariance is large negative #
                     a small covariance #, hard to say
                     the sign is imp & tells us the nature of Relationship
                     Magnitute is diff to judge - we can improve by coefficient of correlation
        Coefficient of correlation - values -1,0,+1, formula - covariance / SD( individual )
                    -1 - negative linear Relationship
                    +1 - perfect positive Relationship
                    0 - no Relationship
                    drawbacks - except for -,0,1 - we cannot imterpret the correlation
                    e.g. -0.4 - negative Relationship & its weak as 0.4 is cose to 0
                        set1 = 0.943 ( positive & close to 1 )
                        set2 = -0.943 ( negative)
                        set3 = -0.189 ( almost no Relationship)
        coefficient of determination - R^2
                    measures the amount of variation in the dependent variable that is 
                    explained by the variation int he indepedent variable
                    e.g r2 = 0.75. 75% of variation is explained by X. 25% is unexplained

General Guidelines for Exploring the data
    1) approx center of the distribution
    2) are they widely dispersed
    3) unimodal, bimodal, or multimodal, where are the peaks & valleys
    4) distribution symmetric, skewed etc.

CH5 - Data Collection & Sampling
    Data Collection - observation, surveys, experiments
    Sampling
            Cost hence sampling 
            Sampling could be biased; make sure that it represents the population in as much as 
            many aspects as possible

            Types
                1) Random Sampling - equaly likely
                2) Stratified Random Sampling
                    Obtained by seperating the population into mutually exclusive strate then simple random sampling 
                3) Cluster Sample
                     simple random sample of groups

    Error of Sampling
        Sampling error & non sampling error
        Sampling Error - error we expect to occur when we make a statement 
            about the population based on the sample statistics.
        Non Sampling Error
            1) Error in data acquisition
            2) Non response error
            3) Selection biased

CH6 - Probability
    Experiment & Outcomes - flip a coin, head or tails
    outcomes to be exhaustive & Mutually exclusive
    Sample space - list of all possible outcomes
    Requirment of Probability
        1) P(O) between 0 & 1
        2) Sum of prob of all outcomes = 1    
    Event
      e.g Grade A = {80 - 100}
      P(Event - pass the course) = P(Grade A) + B + C + D 

    Joint, Marginal & Conditional Probability
        Joint Probability - intersection of 2 events
                P ( A and B )
        Marginal Probability - computed across rows or columns; are so names because 
            they are calculated across the margins
            e.g Top 20 Mba prog , Fund outperforms market
            P(A1 and B1) + P(A1 and B2) - see pg 180
            Conditional Probability - P(B1|A1) A1 is given Probability
            P(A|B) = p(A&B) / p(B)
        Independence - prob one one does not affect the other
            p(A|B) = P(A)
        Union - A or B or Both
        Compliment Rule
            P(Ac) = 1- P(A)
        Multiplication rule - p(A&B) = P(B)*P(A|B)
        Multiplication rule - p(A&B) = P(B)*P(A) - Independent event 
        Addition Rule - P(AorB) = P(A)+P(B) - P(A&B)
        Addition Rule - P(AorB) = P(A)+P(B) - Mutually exclusive 

        Probability Trees
            P(B) = P(A&B) + P(Ac&B)
            Prior Probability - Prior
            Likelihood Probability - beyond this book
            Posterior Probability or revised  - after
            Watch kilian weinbeirger vedios
            Bayes law - replacement for Probability Trees
            P(Ai|B) = P(Ai)P(B|Ai) / (P(A1)P(B|A1) + P(A2)P(B|A2) ...... + P(Ak)P(B|Ak)   )

CH7 - Random Variable & Probability distribution
    Random Variable - Function or rule tht assigns a number to each outcome of an Experiment
    Discrete random variable & continuous random variable
    Probability distribution is a graph or table that describes values of a random variable and the probability associated with it
    P(X=x) or P(x)
    population mean is the weighted avg of all its values. these weghts are probabilities. this is also called expected value of x i.e E(X)

    Population Mean E(X) = mu = sum(xP(X))
    Population variance V(X) = sigma^2 = sum((x-mu)^2 * P(x))

    Laws of Expected value
    E(c) = c 
    E(X+c) =  E(X) + c 
    E(cX) = cE(X)

    Laws of Variance
    V(c) = 0
    V(X+c) =  V(X)
    V(cX) = c^2V(X)

    Sum of 2 variables

    Laws of Expected value & Variance of he sum of 2 variables
    E(X+Y) = E(X) + E(Y)
    V(X+Y) =  V(X) + V(Y) + 2COV(X,Y) ; COV(X,Y) = 0 if X, Y are independent
    
    Binomial Experiment
        Fixed no of trails
        2 possible outcomes
        the trails are independent. outcome of one trail doesnt affect outcome of another

        P(x) = (n! / (x!(n-x)!))Px(1-P)^n-x

    Poisson Rndom Variable
        number of success that occur in a period of time / interval of space

    Poisson Experiment
        the # of success that occur in any interval in independent of the # of success in any other interval
        the prob of success is same for all equal size interval
        the prob of success is proportional to interval size

        P(x) = e-Mu Mu^x / x!

CH8 - Continuous Probability Distributions
    






        